import streamlit as st
import cv2
import numpy as np
from datetime import datetime

# Configure Streamlit page
st.set_page_config(
    page_title="Continuous Video Analytics",
    page_icon="ğŸ“¹",
    layout="wide"
)

def detect_face_opencv(frame):
    """Detect faces using OpenCV"""
    try:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        for (x, y, w, h) in faces:
            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
            cv2.putText(frame, 'Face Detected', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
        
        return frame, len(faces) > 0
    except:
        return frame, False

def analyze_posture_simple(frame):
    """Simple posture analysis"""
    try:
        height, width = frame.shape[:2]
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        center_region = gray[height//3:2*height//3, width//3:2*width//3]
        center_intensity = np.mean(center_region)
        is_centered = center_intensity > 50
        
        cv2.rectangle(frame, (width//3, height//3), (2*width//3, 2*height//3), (0, 255, 0), 2)
        cv2.putText(frame, 'Center Zone', (width//3, height//3-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return frame, is_centered
    except:
        return frame, False

def analyze_gaze_simple(frame, face_detected):
    """Simple gaze analysis"""
    try:
        if not face_detected:
            return frame, False
        
        height, width = frame.shape[:2]
        looking_at_camera = face_detected
        
        if looking_at_camera:
            cv2.putText(frame, 'Looking at Camera', (10, height-20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        return frame, looking_at_camera
    except:
        return frame, False

def main():
    st.title("ğŸ¥ Real-time Video Analytics - Always Running")
    st.markdown("---")
    
    # Sidebar
    st.sidebar.header("âš™ï¸ Settings")
    
    camera_index = st.sidebar.selectbox("Camera Index", [0, 1, 2], index=0)
    
    # Analytics toggles
    st.sidebar.subheader("ğŸ“Š Analytics")
    face_on = st.sidebar.checkbox("Face Detection", True)
    posture_on = st.sidebar.checkbox("Posture Analysis", True)
    gaze_on = st.sidebar.checkbox("Gaze Tracking", True)
    
    # Status indicator
    st.sidebar.success("ğŸŸ¢ ALWAYS RUNNING")
    st.sidebar.info("ğŸ”„ Continuous real-time processing")
    
    # Main layout
    col1, col2 = st.columns([2, 1])
    
    # Video area
    with col1:
        st.subheader("ğŸ“¹ Live Camera Feed")
        video_area = st.empty()
    
    # Analytics area
    with col2:
        st.subheader("ğŸ“Š Real-time Analytics")
        face_display = st.empty()
        posture_display = st.empty()
        gaze_display = st.empty()
        
        st.subheader("ğŸ“‹ Live Status")
        status_display = st.empty()
    
    # ALWAYS RUNNING CAMERA - NO CONTROLS!
    # Capture frame
    cap = cv2.VideoCapture(camera_index)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    if cap.isOpened():
        ret, frame = cap.read()
        
        if ret and frame is not None:
            # Mirror effect
            frame = cv2.flip(frame, 1)
            
            # Analytics
            face_detected = False
            posture_centered = False
            looking_at_camera = False
            
            if face_on:
                frame, face_detected = detect_face_opencv(frame)
            
            if posture_on:
                frame, posture_centered = analyze_posture_simple(frame)
            
            if gaze_on and face_detected:
                frame, looking_at_camera = analyze_gaze_simple(frame, face_detected)
            
            # Add continuous indicator
            timestamp = datetime.now().strftime("%H:%M:%S")
            cv2.putText(frame, f"REAL-TIME | {timestamp}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            cv2.putText(frame, "ALWAYS RUNNING", (10, frame.shape[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Display frame
            video_area.image(frame, channels="BGR", use_column_width=True)
            
            # Update analytics
            face_status = "âœ… Visible" if face_detected else "âŒ Not Found"
            posture_status = "âœ… Centered" if posture_centered else "âš ï¸ Off-Center"
            gaze_status = "âœ… Looking" if looking_at_camera else "âŒ Away"
            
            face_display.metric("ğŸ‘¤ Face", face_status)
            posture_display.metric("ğŸ§ Posture", posture_status)
            gaze_display.metric("ğŸ‘ï¸ Gaze", gaze_status)
            
            # Status display
            status_html = f"""
            <div style="padding: 15px; border-radius: 10px; background-color: #d1ecf1;">
                <h4>ğŸ”„ REAL-TIME PROCESSING</h4>
                <p><strong>Face:</strong> {face_status}</p>
                <p><strong>Posture:</strong> {posture_status}</p>
                <p><strong>Gaze:</strong> {gaze_status}</p>
                <p><strong>Mode:</strong> ğŸŸ¢ Always Running</p>
            </div>
            """
            status_display.markdown(status_html, unsafe_allow_html=True)
            
        else:
            # Camera error - keep trying!
            video_area.warning("ğŸ”„ Camera reconnecting...")
    else:
        video_area.error("âŒ Cannot access camera")
    
    # Release and immediately restart
    cap.release()
    
    # CONTINUOUS REFRESH - ALWAYS RUNNING!
    st.rerun()

if __name__ == "__main__":
    main()
